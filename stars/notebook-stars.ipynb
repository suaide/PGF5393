{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook para classificação de estrelas usando redes neurais com Keras\n",
    "## Alexandre Suaide\n",
    "\n",
    "Este notebook treina uma rede neural MLP usando **Keras/TensorFlow** para classificar tipos de estrelas a partir de suas propriedades físicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se estiver no Google Colab, descomente a linha abaixo para instalar dependências:\n",
    "# !pip install mdsdata tensorflow scikit-learn seaborn joblib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa os módulos necessários\n",
    "# dependendo da versão do TensoFlow, aparece um monte de warnings\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lê o dataset do arquivo CSV e coloca em um dataframe do Pandas\n",
    "\n",
    "filename = \"data-stars.csv\" \n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz o Diagrama H-R\n",
    "\n",
    "lx = 'Temperature (K)'\n",
    "ly = 'Luminosity (L/Lo)'\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(df[lx], df[ly], s=20, alpha=0.6)\n",
    "plt.yscale('log')\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel(lx)\n",
    "plt.ylabel(ly)\n",
    "plt.title('Diagrama H-R')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determina quais features serão utilizados e o target para treinamento\n",
    "\n",
    "FEATURES = ['Temperature (K)', 'Luminosity (L/Lo)', 'Radius (R/Ro)', 'Absolute magnitude (Mv)']\n",
    "TARGET = 'Star category'\n",
    "\n",
    "X = df[FEATURES].values\n",
    "y_raw = df[TARGET].values\n",
    "\n",
    "# Codifica os rótulos, já que o Target é uma variável de texto\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "class_names = list(le.classes_)\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# divisão do dataset em treino, teste e validação. \n",
    "# as variáveis abaixo determinam as frações\n",
    "\n",
    "train_ratio = 0.50\n",
    "test_ratio = 0.35\n",
    "validation_ratio = 0.15\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio, stratify = y, random_state = random_state)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify = y_test, random_state = random_state) \n",
    "\n",
    "print(f\"train = {len(X_train)} \\ntest = {len(X_test)} \\nval = {len(X_val)}\")\n",
    "\n",
    "# Normaliza as variáveis usando o scaler padrão\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo no Keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(len(FEATURES),)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinamento da rede\n",
    "# verbose = 0, 1 ou 2 indica a quantidade de print\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz figura da perda e da acurácia para cada época\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='treino')\n",
    "plt.plot(history.history['val_loss'], label='validação')\n",
    "plt.title('Perda')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='treino')\n",
    "plt.plot(history.history['val_accuracy'], label='validação')\n",
    "plt.title('Acurácia')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o dataset de teste\n",
    "# obtém a matriz de confusão\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "plt.xlabel('Predição')\n",
    "plt.ylabel('Verdade')\n",
    "plt.title('Matriz de confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer predições e printar o resultado\n",
    "\n",
    "n = len(X_test)\n",
    "samples = X_test[:n]\n",
    "pred_labels = le.inverse_transform(np.argmax(model.predict(samples), axis=1))\n",
    "true_labels = le.inverse_transform(y_test[:n])\n",
    "\n",
    "for i in range(n):\n",
    "    print(f\"Pred: {pred_labels[i]}  \\t Verd: {true_labels[i]}  \\t {pred_labels[i] == true_labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salva o modelo para uso futuro em novos dados. Dai não precisa treinar a rede novamente\n",
    "\n",
    "model.save(\"star_classifier_keras.keras\")\n",
    "print(\"Modelo gravado como star_classifier_keras.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
